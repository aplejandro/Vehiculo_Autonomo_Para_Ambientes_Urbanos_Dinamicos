{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Percepcion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ygs2TAEr20Wn",
        "outputId": "f967f60b-4441-4a85-aa67-f1dd726a2f80"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MPJN7hc3brD"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/output_maps /content/"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWYKYtmD53EM"
      },
      "source": [
        "!cp /content/drive/MyDrive/image_functions.py /content/\r\n",
        "!cp /content/drive/MyDrive/pipeline.py /content/"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SET39XbQ6Uik"
      },
      "source": [
        "!cp /content/drive/MyDrive/laneline.py /content/"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llrGnvY93zHv"
      },
      "source": [
        "mkdir output_lane"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmnTw8BN2nqX"
      },
      "source": [
        "Detección del Carril"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl5AljQV0k3f",
        "outputId": "1e72eb15-6c80-4123-ae92-6bf9e017af0b"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.image as mpimg\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "import os\r\n",
        "import pickle\r\n",
        "import random\r\n",
        "import glob\r\n",
        "\r\n",
        "import laneline\r\n",
        "from image_functions import *\r\n",
        "from pipeline import *\r\n",
        "\r\n",
        "from collections import deque\r\n",
        "from moviepy.editor import VideoFileClip\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "path = \"/content/output_maps/\"\r\n",
        "\r\n",
        "\r\n",
        "tst_imgs, tst_names = read_all_imgs(path)\r\n",
        "\r\n",
        "\r\n",
        "print(\"Analizing \" + str(len(tst_imgs)) + \" images\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#New color mask 2\r\n",
        "print(\"Applying Color Mask\")\r\n",
        "ncmask_2 = []\r\n",
        "for img in tst_imgs:\r\n",
        "    new_color_masked = new_color_mask_2(img)\r\n",
        "    ncmask_2.append(new_color_masked)\r\n",
        "print(\"Done\")\r\n",
        "\r\n",
        "print(\"Applying Direction Gradient\")\r\n",
        "direction = []\r\n",
        "for img in ncmask_2:\r\n",
        "    dir_img = dir_thresh(img, kernel_size = 7, thresh = (-0.3,0.3))\r\n",
        "    direction.append(dir_img)\r\n",
        "print(\"Done\")\r\n",
        "\r\n",
        "print(\"Applying Median Filter\")\r\n",
        "median_bin = []\r\n",
        "for img in direction:\r\n",
        "    median_img = MEDIAN_BLUR(img, kernel_size = 11)\r\n",
        "    #median_img = MEDIAN_BLUR(median_img, kernel_size = 3)\r\n",
        "    median_img = inverse(median_img)\r\n",
        "    median_bin.append(median_img)\r\n",
        "print(\"Done\")\r\n",
        "\r\n",
        "perspective = []\r\n",
        "Minverse = []\r\n",
        "print(\"Applying Perspective Transform\")\r\n",
        "for img in median_bin:\r\n",
        "    perspective_img,M,Minv = perspective_transform(img)\r\n",
        "    perspective.append(perspective_img)\r\n",
        "    Minverse.append(Minv)\r\n",
        "print(\"Done\")\r\n",
        "\r\n",
        "#Processed images\r\n",
        "raw = []\r\n",
        "left_raw = []\r\n",
        "right_raw = []\r\n",
        "print(\"Detecting Lines\")\r\n",
        "for img in perspective:\r\n",
        "    left_fit_raw, right_fit_raw, out_img_raw = find_line_raw(img, return_img=True, plot_boxes=True, plot_line=True)\r\n",
        "    raw.append(out_img_raw)\r\n",
        "    left_raw.append(left_fit_raw)\r\n",
        "    right_raw.append(right_fit_raw)\r\n",
        "print(\"Done\")\r\n",
        "\r\n",
        "\r\n",
        "print(\"Processing Images\")\r\n",
        "processed = []\r\n",
        "i = 0\r\n",
        "for img in raw:\r\n",
        "    print(\"Image: \" + str(i))\r\n",
        "    processed_img = plot_lanelines(tst_imgs[i],perspective[i],left_raw[i], right_raw[i], Minverse[i], img)\r\n",
        "    mpimg.imsave('/content/output_lane/' + tst_names[i], processed_img)\r\n",
        "    processed.append(processed_img)\r\n",
        "    i += 1\r\n",
        "print(\"Done\")\r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2703360/45929032 bytes (5.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5488640/45929032 bytes (12.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b8421376/45929032 bytes (18.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b11329536/45929032 bytes (24.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b14499840/45929032 bytes (31.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b17506304/45929032 bytes (38.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b20570112/45929032 bytes (44.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b23199744/45929032 bytes (50.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b26255360/45929032 bytes (57.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b29392896/45929032 bytes (64.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b32497664/45929032 bytes (70.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b35422208/45929032 bytes (77.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b38567936/45929032 bytes (84.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b41902080/45929032 bytes (91.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45080576/45929032 bytes (98.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n",
            "Analizing 12 images\n",
            "Applying Color Mask\n",
            "Done\n",
            "Applying Direction Gradient\n",
            "Done\n",
            "Applying Median Filter\n",
            "Done\n",
            "Applying Perspective Transform\n",
            "Done\n",
            "Detecting Lines\n",
            "Done\n",
            "Processing Images\n",
            "Image: 0\n",
            "Image: 1\n",
            "Image: 2\n",
            "Image: 3\n",
            "Image: 4\n",
            "Image: 5\n",
            "Image: 6\n",
            "Image: 7\n",
            "Image: 8\n",
            "Image: 9\n",
            "Image: 10\n",
            "Image: 11\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT60FW2v4A36"
      },
      "source": [
        "Detección de Objetos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3APvu8D54Flr",
        "outputId": "3cb21537-7a8b-47a7-8074-a032a9a21e35"
      },
      "source": [
        "!pip install numpy==1.16.2\r\n",
        "import numpy as np\r\n",
        "print(np.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.16.2 in /usr/local/lib/python3.6/dist-packages (1.16.2)\n",
            "1.16.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DCMSYke4Oe_"
      },
      "source": [
        "input_dir = '/content/output_lane'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv_DRVWM4UgT"
      },
      "source": [
        "!mkdir /content/output_objetos\r\n",
        "!mkdir /content/output_objetos/detections_images\r\n",
        "!mkdir /content/output_objetos/detections_txt"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSODoDui4u4q",
        "outputId": "33860f8e-d620-47bd-8b21-c807a5e345ea"
      },
      "source": [
        "!git clone https://gitlab.com/victorvirgilio/yolov3-model.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov3-model'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 41 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (41/41), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88iCmeye45Bp",
        "outputId": "3741cd25-1b61-422d-b038-eefbed3294bf"
      },
      "source": [
        "pip uninstall tensorflow"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.4.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.4.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYbhJsE746-4",
        "outputId": "b56b1906-ef9c-4179-94ec-9709629352fd"
      },
      "source": [
        "pip install tensorflow==1.6.0"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/0f/fbd8bb92459c75db93040f80702ebe4ba83a52cdb6ad930654c31dc0b711/tensorflow-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (45.8MB)\n",
            "\u001b[K     |████████████████████████████████| 45.9MB 104kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.6.0) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.6.0) (3.12.4)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.6.0) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.6.0) (0.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.6.0) (1.32.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.6.0) (1.15.0)\n",
            "Collecting tensorboard<1.7.0,>=1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/67/a8c91665987d359211dcdca5c8b2a7c1e0876eb0702a4383c1e4ff76228d/tensorboard-1.6.0-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 45.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.6.0) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.6.0) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.6.0) (1.16.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow==1.6.0) (51.1.1)\n",
            "Collecting html5lib==0.9999999\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 36.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow==1.6.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow==1.6.0) (3.3.3)\n",
            "Collecting bleach==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.7.0,>=1.6.0->tensorflow==1.6.0) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.7.0,>=1.6.0->tensorflow==1.6.0) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.7.0,>=1.6.0->tensorflow==1.6.0) (3.7.4.3)\n",
            "Building wheels for collected packages: html5lib\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107222 sha256=1e748471c3c26dcb98a6efb56adce6f842c637ec4240745354c118deaac8766b\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built html5lib\n",
            "Installing collected packages: html5lib, bleach, tensorboard, tensorflow\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 3.2.1\n",
            "    Uninstalling bleach-3.2.1:\n",
            "      Successfully uninstalled bleach-3.2.1\n",
            "  Found existing installation: tensorboard 2.4.0\n",
            "    Uninstalling tensorboard-2.4.0:\n",
            "      Successfully uninstalled tensorboard-2.4.0\n",
            "Successfully installed bleach-1.5.0 html5lib-0.9999999 tensorboard-1.6.0 tensorflow-1.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psraB5Px5ADL",
        "outputId": "cf0f2afd-0fae-4096-bfe2-2eea803a30e1"
      },
      "source": [
        "pip uninstall keras"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Keras-2.4.3:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/Keras-2.4.3.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/docs/*\n",
            "    /usr/local/lib/python3.6/dist-packages/keras/*\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.6/dist-packages/docs/md_autogen.py\n",
            "    /usr/local/lib/python3.6/dist-packages/docs/update_docs.py\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled Keras-2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NavlGn65EZ7",
        "outputId": "e967c131-21dc-4801-81b5-cec501b2e3f2"
      },
      "source": [
        "pip install keras==2.1.5"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.1.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/65/e4aff762b8696ec0626a6654b1e73b396fcc8b7cc6b98d78a1bc53b85b48/Keras-2.1.5-py2.py3-none-any.whl (334kB)\n",
            "\r\u001b[K     |█                               | 10kB 10.9MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 14.9MB/s eta 0:00:01\r\u001b[K     |███                             | 30kB 17.0MB/s eta 0:00:01\r\u001b[K     |████                            | 40kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 51kB 17.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 61kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 71kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 81kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 92kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 102kB 11.3MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 112kB 11.3MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 122kB 11.3MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 133kB 11.3MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 143kB 11.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 153kB 11.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 163kB 11.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 174kB 11.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 184kB 11.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 194kB 11.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 204kB 11.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 215kB 11.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 225kB 11.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 235kB 11.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 245kB 11.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 256kB 11.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 266kB 11.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 276kB 11.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 286kB 11.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 296kB 11.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 307kB 11.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 317kB 11.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 327kB 11.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 337kB 11.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.16.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.4.1)\n",
            "Installing collected packages: keras\n",
            "Successfully installed keras-2.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr0ycshh4yeg",
        "outputId": "e136f709-c65e-48fe-9123-041c621b6d01"
      },
      "source": [
        "%cd yolov3-model\r\n",
        "!ls"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/yolov3-model\n",
            "detector  yolov3.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQkQqvlY5Idb",
        "outputId": "070c925d-8be9-43fb-ca5d-4366861d5c85"
      },
      "source": [
        "from detector.yolo import YOLO\r\n",
        "\r\n",
        "import moviepy.editor as mpy\r\n",
        "import time\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "yolo = YOLO(model_path = 'yolov3.h5' , \r\n",
        "        anchors_path = 'detector/yolo_anchors.txt',\r\n",
        "        classes_path = 'detector/coco_classes.txt',\r\n",
        "        score = 0.8,\r\n",
        "        iou = 0.7,\r\n",
        "        model_image_size = (608, 608))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "yolov3.h5 model, anchors, and classes loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUTgwWeB5Liw"
      },
      "source": [
        "import cv2\r\n",
        "import os\r\n",
        "import glob\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "def draw_boxes(img, boxes):\r\n",
        "    for box in boxes:\r\n",
        "        cv2.rectangle(img, box[0], box[1], (0,0,255), 2)\r\n",
        "    return Image.fromarray(np.uint8(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQt8jZkh5OjA",
        "outputId": "a0e83cc6-9777-4781-ace4-36435fb07d33"
      },
      "source": [
        "names = []\r\n",
        "names = glob.glob('/content/output_lane/*')\r\n",
        "print(names)       "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/output_lane/00006528.png', '/content/output_lane/00006905.png', '/content/output_lane/00006757.png', '/content/output_lane/00002566.png', '/content/output_lane/00003397.png', '/content/output_lane/00005419.png', '/content/output_lane/00008398.png', '/content/output_lane/00004430.png', '/content/output_lane/00005707.png', '/content/output_lane/00006000.png', '/content/output_lane/00005398.png', '/content/output_lane/00002211.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt8zNBQY7jug"
      },
      "source": [
        "output_dir = '/content/output_objetos/'"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH1XfTuw5Smr",
        "outputId": "f84ea032-4a14-4463-8536-1f69bdbc1925"
      },
      "source": [
        "import time\r\n",
        "import glob\r\n",
        "from keras.preprocessing import image\r\n",
        "\r\n",
        "save = True\r\n",
        "\r\n",
        "# names = glob.glob(input_dir + '*.png')[:5]\r\n",
        "print('Cantidad de imágenes:   {0}\\n\\n'.format(len(names)))\r\n",
        "\r\n",
        "k = 0\r\n",
        "yolov3_detections = {}\r\n",
        "times = []\r\n",
        "print('\\n***** ***** ***** Inicio de la detección ***** ***** *****\\n')\r\n",
        "for filename in names:\r\n",
        "\r\n",
        "    img = image.load_img(filename)\r\n",
        "    # Get time\r\n",
        "    start = time.time()\r\n",
        "    dimg, out_boxes, out_scores, out_classes = yolo.detect_image(img)\r\n",
        "    end = time.time()\r\n",
        "    times.append(end - start)\r\n",
        "\r\n",
        "    #print(\"Detecto \" + str(len(out_scores)) + \" objetos\")\r\n",
        "    name = filename.split('/')[-1]\r\n",
        "    name_f = name.split('.')[0]\r\n",
        "    f = open(output_dir + \"detections_txt/\" + name_f + \".txt\", \"w\")\r\n",
        "    for i in range(len(out_classes)):\r\n",
        "      if out_classes[i] == 0:\r\n",
        "        #print('Person' + ',' + str(int(out_boxes[i][0])) + ',' + str(int(out_boxes[i][1])) + ',' + str(int(out_boxes[i][2])) + ',' + str(int(out_boxes[i][3])) + ',' + str(out_scores[i]))\r\n",
        "        f.write('Person' + ',' + str(int(out_boxes[i][0])) + ',' + str(int(out_boxes[i][1])) + ',' + str(int(out_boxes[i][2])) + ',' + str(int(out_boxes[i][3])) + ',' + str(out_scores[i]))\r\n",
        "      elif out_classes[i] == 1 or out_classes[i] == 2 or out_classes[i] == 3 or out_classes[i] == 5 or out_classes[i] == 7:\r\n",
        "        #print('Car' + ',' + str(int(out_boxes[i][0])) + ',' + str(int(out_boxes[i][1])) + ',' + str(int(out_boxes[i][2])) + ',' + str(int(out_boxes[i][3])) + ',' + str(out_scores[i]))\r\n",
        "        f.write('Car' + ',' + str(int(out_boxes[i][0])) + ',' + str(int(out_boxes[i][1])) + ',' + str(int(out_boxes[i][2])) + ',' + str(int(out_boxes[i][3])) + ',' + str(out_scores[i]))\r\n",
        "      elif out_classes[i] == 9:\r\n",
        "        #print('Traffic Light' + ',' + str(int(out_boxes[i][0])) + ',' + str(int(out_boxes[i][1])) + ',' + str(int(out_boxes[i][2])) + ',' + str(int(out_boxes[i][3])) + ',' + str(out_scores[i]))\r\n",
        "        f.write('Traffic Light' + ',' + str(int(out_boxes[i][0])) + ',' + str(int(out_boxes[i][1])) + ',' + str(int(out_boxes[i][2])) + ',' + str(int(out_boxes[i][3])) + ',' + str(out_scores[i]))\r\n",
        "      else:\r\n",
        "        #print('Other' + ',' + str(int(out_boxes[i][0])) + ',' + str(int(out_boxes[i][1])) + ',' + str(int(out_boxes[i][2])) + ',' + str(int(out_boxes[i][3])) + ',' + str(out_scores[i]))\r\n",
        "        f.write('Other' + ',' + str(int(out_boxes[i][0])) + ',' + str(int(out_boxes[i][1])) + ',' + str(int(out_boxes[i][2])) + ',' + str(int(out_boxes[i][3])) + ',' + str(out_scores[i]))\r\n",
        "      f.write('\\n')\r\n",
        "    f.close()\r\n",
        "\r\n",
        "\r\n",
        "    ouput_name = filename.split('/')\r\n",
        "    name = ouput_name[-1]\r\n",
        "    dimg.save(output_dir + 'detections_images/' + name)\r\n",
        "    print('\\n***** Imagen numero', k, 'fue procesada. *****')\r\n",
        "    k+=1\r\n",
        "\r\n",
        "\r\n",
        "tiempo_promedio = sum(times) / len(times)\r\n",
        "print('\\n\\n\\tPromedio de inferencia: {0}\\n'.format(tiempo_promedio))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cantidad de imágenes:   12\n",
            "\n",
            "\n",
            "\n",
            "***** ***** ***** Inicio de la detección ***** ***** *****\n",
            "\n",
            "\n",
            "***** Imagen numero 0 fue procesada. *****\n",
            "\n",
            "***** Imagen numero 1 fue procesada. *****\n",
            "\n",
            "***** Imagen numero 2 fue procesada. *****\n",
            "\n",
            "***** Imagen numero 3 fue procesada. *****\n",
            "\n",
            "***** Imagen numero 4 fue procesada. *****\n",
            "\n",
            "***** Imagen numero 5 fue procesada. *****\n",
            "\n",
            "***** Imagen numero 6 fue procesada. *****\n",
            "\n",
            "***** Imagen numero 7 fue procesada. *****\n",
            "\n",
            "***** Imagen numero 8 fue procesada. *****\n",
            "\n",
            "***** Imagen numero 9 fue procesada. *****\n",
            "\n",
            "***** Imagen numero 10 fue procesada. *****\n",
            "\n",
            "***** Imagen numero 11 fue procesada. *****\n",
            "\n",
            "\n",
            "\tPromedio de inferencia: 7.412349800268809\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjJE4RNB-Mb-"
      },
      "source": [
        "Detección del Estado del Semáforo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rWNLln6-sVe",
        "outputId": "16162cd5-9e81-45fe-b8d0-441a262fbb75"
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdqRMp00-kwJ"
      },
      "source": [
        "mkdir output_tl"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9bH77tZ-3UO"
      },
      "source": [
        "output_tl= '/content/output_tl/'"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD1o9Q_v7log",
        "outputId": "d9805c7f-38ec-47a6-8566-cc5c73590924"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.image as mpimg\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "import os\r\n",
        "import pickle\r\n",
        "import random\r\n",
        "import glob\r\n",
        "import csv\r\n",
        "\r\n",
        "import laneline\r\n",
        "from image_functions import *\r\n",
        "from pipeline import *\r\n",
        "\r\n",
        "\r\n",
        "def color_mask(img):\r\n",
        "    \"\"\"\r\n",
        "    New color mask fucntion that combines three different color space filters\r\n",
        "    to increasee detection accuracy.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    hsv = HSV(img)\r\n",
        "    hls = HLS(img)\r\n",
        "    binary = np.zeros_like(img[:, :, 0])\r\n",
        "\r\n",
        "    # Green filter\r\n",
        "    #RGB\r\n",
        "    lower_green = (90,235,70)\r\n",
        "    upper_green = (210,255,170)\r\n",
        "    rgb_g_mask = cv2.inRange(img, lower_green, upper_green)\r\n",
        "    #HSV\r\n",
        "    lower_green_hsv = (45, 80, 230)\r\n",
        "    upper_green_hsv = (60, 180, 255)\r\n",
        "    hsv_g_mask = cv2.inRange(hsv, lower_green_hsv, upper_green_hsv)\r\n",
        "    #HLS\r\n",
        "    lower_green_hls = (45,150,205)\r\n",
        "    upper_green_hls = (60,220,255)\r\n",
        "    hls_g_mask = cv2.inRange(hls, lower_green_hls, upper_green_hls)\r\n",
        "    mask_g = cv2.bitwise_and(hsv_g_mask, hls_g_mask, rgb_g_mask)\r\n",
        "    green_filter = binary | mask_g\r\n",
        "\r\n",
        "    # Red filter\r\n",
        "    #RGB\r\n",
        "    lower_red = (240,150,75)\r\n",
        "    upper_red = (255,180,95)\r\n",
        "    rgb_r_mask = cv2.inRange(img, lower_red, upper_red)\r\n",
        "    #HSV\r\n",
        "    lower_red_hsv = (0, 155, 240)\r\n",
        "    upper_red_hsv = (20, 195, 255)\r\n",
        "    hsv_r_mask = cv2.inRange(hsv, lower_red_hsv, upper_red_hsv)\r\n",
        "    #HLS\r\n",
        "    lower_red_hls = (0,160,240)\r\n",
        "    upper_red_hls = (20,190,255)\r\n",
        "    hls_r_mask = cv2.inRange(hls, lower_red_hls, upper_red_hls)\r\n",
        "\r\n",
        "    mask_r = cv2.bitwise_and(hsv_r_mask, hls_r_mask, rgb_r_mask)\r\n",
        "    red_filter = binary | mask_r\r\n",
        "\r\n",
        "    return green_filter, red_filter\r\n",
        "\r\n",
        "def HLS(img):\r\n",
        "    return cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\r\n",
        "\r\n",
        "def HSV(img):\r\n",
        "    return cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\r\n",
        "\r\n",
        "def read_all_imgs(path, color=cv2.IMREAD_COLOR):\r\n",
        "\r\n",
        "    images = []\r\n",
        "    filenames = []\r\n",
        "\r\n",
        "    filelist = os.listdir(path)\r\n",
        "    for file in filelist:\r\n",
        "\r\n",
        "        try:\r\n",
        "            img = cv2.imread(path + file, color)\r\n",
        "        except:\r\n",
        "            img = None\r\n",
        "\r\n",
        "        if img is not None:\r\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
        "            images.append(img)\r\n",
        "            filenames.append(file)\r\n",
        "\r\n",
        "    return images, filenames\r\n",
        "\r\n",
        "def read_all_txt(path):\r\n",
        "\r\n",
        "    filenames = []\r\n",
        "\r\n",
        "    filelist = os.listdir(path)\r\n",
        "    for file in filelist:\r\n",
        "        filenames.append(file)\r\n",
        "\r\n",
        "    return filenames\r\n",
        "\r\n",
        "def is_file_empty(file_path):\r\n",
        "    \"\"\" Check if file is empty by confirming if its size is 0 bytes\"\"\"\r\n",
        "    # Check if file exist and it is empty\r\n",
        "    return os.path.exists(file_path) and os.stat(file_path).st_size == 0\r\n",
        "\r\n",
        "def traffic_light_state(img, y_top, x_left, y_bottom, x_right):\r\n",
        "    ROI = img[y_top:y_bottom, x_left:x_right]\r\n",
        "    green, red = color_mask(ROI)\r\n",
        "    nz_green = green.nonzero()\r\n",
        "    nz_red = red.nonzero()\r\n",
        "    nzg = nz_green[0]\r\n",
        "    nzr = nz_red[0]\r\n",
        "    if len(nzg) > len(nzr):\r\n",
        "        return True\r\n",
        "    else:\r\n",
        "        return False\r\n",
        "\r\n",
        "def all_trafic_light_state(img, y_top, x_left, y_bottom, x_right):\r\n",
        "    if x_left > 300 and x_left < 1200:\r\n",
        "        base = x_right - x_left\r\n",
        "        height = y_bottom - y_top\r\n",
        "        area = base * height\r\n",
        "        if area > 140:\r\n",
        "            ROI = img[y_top:y_bottom, x_left:x_right]\r\n",
        "            green, red = color_mask(ROI)\r\n",
        "            nz_green = green.nonzero()\r\n",
        "            nz_red = red.nonzero()\r\n",
        "            nzg = nz_green[0]\r\n",
        "            nzr = nz_red[0]\r\n",
        "            if len(nzg) > len(nzr):\r\n",
        "                return 1\r\n",
        "            else:\r\n",
        "                return -1\r\n",
        "        else:\r\n",
        "            return 0\r\n",
        "    else:\r\n",
        "        return 0\r\n",
        "\r\n",
        "print(\"Reading images...\")\r\n",
        "path_detected = \"/content/output_objetos/detections_images/\"\r\n",
        "path_original = \"/content/output_maps/\"\r\n",
        "path_txt = \"/content/output_objetos/detections_txt/\"\r\n",
        "\r\n",
        "\r\n",
        "detected_images, detected_images_names = read_all_imgs(path_detected)\r\n",
        "print(detected_images_names)\r\n",
        "original_images, original_images_names = read_all_imgs(path_original)\r\n",
        "print(original_images_names)\r\n",
        "txt_names = read_all_txt(path_txt)\r\n",
        "#print(txt_names)\r\n",
        "names_txt = []\r\n",
        "for name in original_images_names:\r\n",
        "  name_f=name.split('.')[0]+'.txt'\r\n",
        "  names_txt.append(name_f)\r\n",
        "# names_txt.append(txt_names[8])\r\n",
        "# names_txt.append(txt_names[3])\r\n",
        "# names_txt.append(txt_names[0])\r\n",
        "# names_txt.append(txt_names[9])\r\n",
        "# names_txt.append(txt_names[1])\r\n",
        "# names_txt.append(txt_names[7])\r\n",
        "# names_txt.append(txt_names[10])\r\n",
        "# names_txt.append(txt_names[4])\r\n",
        "# names_txt.append(txt_names[3])\r\n",
        "# names_txt.append(txt_names[5])\r\n",
        "# names_txt.append(txt_names[11])\r\n",
        "# names_txt.append(txt_names[2])\r\n",
        "print(names_txt)\r\n",
        "\r\n",
        "print(\"Analizing \" + str(len(detected_images)) + \" detected images\")\r\n",
        "print(\"Analizing \" + str(len(original_images)) + \" original images\")\r\n",
        "print(\"Analizing \" + str(len(names_txt)) + \" text files\")\r\n",
        "\r\n",
        "# for i in range(len(txt_names)):\r\n",
        "#     name = original_images_names[i].split('/')[-1]\r\n",
        "#     print(\"Imagen: \" + name)\r\n",
        "#     is_empty = is_file_empty(txt_names[i])\r\n",
        "#     if is_empty:\r\n",
        "#         print(\"Traffic Light Not Detected\")\r\n",
        "#         continue\r\n",
        "#     else:\r\n",
        "#         with open(txt_names[i], 'r') as file:\r\n",
        "#             reader = csv.reader(file)\r\n",
        "#             tl_flag = False\r\n",
        "#             for row in reader:\r\n",
        "#                 if row[0] == \"Traffic Light\":\r\n",
        "#                     traffic_light_row = row\r\n",
        "#                     print(traffic_light_row)\r\n",
        "#                     tl_flag = True\r\n",
        "#                     break\r\n",
        "#             if tl_flag:\r\n",
        "#                 if int(traffic_light_row[2]) > 300 and int(traffic_light_row[2]) < 1000:\r\n",
        "#                     base = int(traffic_light_row[4]) - int(traffic_light_row[2])\r\n",
        "#                     height = int(traffic_light_row[3]) - int(traffic_light_row[1])\r\n",
        "#                     area = base * height\r\n",
        "#                     if area < 140:\r\n",
        "#                         print(\"Traffic Light Detected but too small to analyze\")\r\n",
        "#                     else:\r\n",
        "#                         state = traffic_light_state(original_images[i],int(traffic_light_row[1]),int(traffic_light_row[2]),int(traffic_light_row[3]),int(traffic_light_row[4]))\r\n",
        "#                         if state:\r\n",
        "#                             print(\"Traffic Light Detected: Go\")\r\n",
        "#                         else:\r\n",
        "#                             print(\"Traffic Light Detected: Stop\")\r\n",
        "#                 else:\r\n",
        "#                     print(\"Traffic Light Detected but not in range\")\r\n",
        "#             else:\r\n",
        "#                 print(\"Traffic Light Not Detected\")\r\n",
        "\r\n",
        "\r\n",
        "font = cv2.FONT_HERSHEY_SIMPLEX\r\n",
        "org = (50, 50)\r\n",
        "fontScale = 1\r\n",
        "thickness = 2\r\n",
        "\r\n",
        "for i in range(len(names_txt)):\r\n",
        "    name = detected_images_names[i].split('/')[-1]\r\n",
        "    print(\"Imagen: \" + name)\r\n",
        "    is_empty = is_file_empty(path_txt + names_txt[i])\r\n",
        "    if is_empty:\r\n",
        "        print(\"Traffic Light Not Detected\")\r\n",
        "        new_image = cv2.putText(detected_images[i], 'Traffic Light Not Detected', org, font, fontScale, (255,255,255), thickness, cv2.LINE_AA)\r\n",
        "    else:\r\n",
        "        with open(path_txt + names_txt[i], 'r') as file:\r\n",
        "            reader = csv.reader(file)\r\n",
        "            traffic_light_row = []\r\n",
        "            tl_flag = False\r\n",
        "            for row in reader:\r\n",
        "                if row[0] == \"Traffic Light\":\r\n",
        "                    tl_flag = True\r\n",
        "                    traffic_light_row.append(row)\r\n",
        "            if tl_flag:\r\n",
        "                sum_state = 0\r\n",
        "                for tl in traffic_light_row:\r\n",
        "                    state = all_trafic_light_state(original_images[i],int(tl[1]),int(tl[2]),int(tl[3]),int(tl[4]))\r\n",
        "                    #print(state)\r\n",
        "                    sum_state += state\r\n",
        "                if sum_state == 0:\r\n",
        "                    print(\"Traffic Light detected but too small to analyze or not in range\")\r\n",
        "                    new_image = cv2.putText(detected_images[i], 'Traffic Light Detected but too small to analyze or not in range', org, font, fontScale, (255,255,255), thickness, cv2.LINE_AA)\r\n",
        "                elif sum_state > 0:\r\n",
        "                    print(\"Traffic Light Detected: Go\")\r\n",
        "                    new_image = cv2.putText(detected_images[i], 'Traffic Light Detected: Go', org, font, fontScale, (0,255,0), thickness, cv2.LINE_AA)\r\n",
        "                else:\r\n",
        "                    print(\"Traffic Light Detected: Stop\")\r\n",
        "                    new_image = cv2.putText(detected_images[i], 'Traffic Light Detected: Stop', org, font, fontScale, (255,0,0), thickness, cv2.LINE_AA)\r\n",
        "            else:\r\n",
        "                print(\"Traffic Light Not Detected\")\r\n",
        "                new_image = cv2.putText(detected_images[i], 'Traffic Light Not Detected', org, font, fontScale, (255,255,255), thickness, cv2.LINE_AA)\r\n",
        "    mpimg.imsave(output_tl + name, new_image )\r\n",
        "    print(name)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading images...\n",
            "['00006528.png', '00006905.png', '00006757.png', '00002566.png', '00003397.png', '00005419.png', '00008398.png', '00004430.png', '00005707.png', '00006000.png', '00005398.png', '00002211.png']\n",
            "['00006528.png', '00006905.png', '00006757.png', '00002566.png', '00003397.png', '00005419.png', '00008398.png', '00004430.png', '00005707.png', '00006000.png', '00005398.png', '00002211.png']\n",
            "['00006528.txt', '00006905.txt', '00006757.txt', '00002566.txt', '00003397.txt', '00005419.txt', '00008398.txt', '00004430.txt', '00005707.txt', '00006000.txt', '00005398.txt', '00002211.txt']\n",
            "Analizing 12 detected images\n",
            "Analizing 12 original images\n",
            "Analizing 12 text files\n",
            "Imagen: 00006528.png\n",
            "Traffic Light Detected: Stop\n",
            "00006528.png\n",
            "Imagen: 00006905.png\n",
            "Traffic Light Detected: Stop\n",
            "00006905.png\n",
            "Imagen: 00006757.png\n",
            "Traffic Light Not Detected\n",
            "00006757.png\n",
            "Imagen: 00002566.png\n",
            "Traffic Light Not Detected\n",
            "00002566.png\n",
            "Imagen: 00003397.png\n",
            "Traffic Light Not Detected\n",
            "00003397.png\n",
            "Imagen: 00005419.png\n",
            "Traffic Light Not Detected\n",
            "00005419.png\n",
            "Imagen: 00008398.png\n",
            "Traffic Light Not Detected\n",
            "00008398.png\n",
            "Imagen: 00004430.png\n",
            "Traffic Light Not Detected\n",
            "00004430.png\n",
            "Imagen: 00005707.png\n",
            "Traffic Light Not Detected\n",
            "00005707.png\n",
            "Imagen: 00006000.png\n",
            "Traffic Light Not Detected\n",
            "00006000.png\n",
            "Imagen: 00005398.png\n",
            "Traffic Light Not Detected\n",
            "00005398.png\n",
            "Imagen: 00002211.png\n",
            "Traffic Light Not Detected\n",
            "00002211.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t6AKi0lHwwM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}